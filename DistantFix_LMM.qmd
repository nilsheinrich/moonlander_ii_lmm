---
title: "Nils Wendel Heinrich: Distant Fixations"
subtitle: "Moonlander II - Analysis"
author: "Nils Wendel Heinrich"
date: "2023-10-24"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options:
  chunk_output_type: console
jupyter: julia-1.9
---

# Description
2 Covariates (continuous variables we believe affect the predicted variable) - N_visible_obstacles & N_visible_drift_tiles
1 Fixed Effect (categorical variable) -block

# Setup

## Packages

```{julia}
#| label: packages

using Arrow
using AlgebraOfGraphics
using CairoMakie
using DataFrames
using DataFrameMacros
using MixedModels
using MixedModelsMakie
using Random

CairoMakie.activate!(; type="svg");
```

```{julia}
#| label: constants
const RNG = MersenneTwister(36)
N_iterations = 10000

const AoG = AlgebraOfGraphics;
```

# Modeling fixation duration

## Code book
possible random effect: **ID** (the subject itself).

```{julia}
#| label: data

my_data = DataFrame(Arrow.Table("data/Experiment2_DistantFixations.arrow"))
my_data = dropmissing(my_data, [:N_visible_obstacles, :N_visible_drift_tiles])

# Filtering saccades with no amplitude
my_data = my_data[(my_data.fixation_duration .>= 0.0125), :]
#eliminating fixations outside of game boarders
my_data = my_data[(my_data.distance_to_spaceship .> 16.63762484977781), :]

describe(my_data)
```

### Contrasts

We will declare **ID** as a grouping variable as well as define the effects coding for the discrete covariateblock.

#### Hypothesis Coding
```{julia}
my_cake = Dict(
  :ID => Grouping(),
  :block => HypothesisCoding(
    [
      -1 +1 0
      -1 0 +1
    ];
    levels=["no_drift", "fake", "invisible"],
    labels=["fake-none", "invisible-none"],
  ),
);
```

# Modeling fixation duration

## Building various models

### Only varying intercept LMM

Varying intercept for **ID**:
```{julia}
#| label: m_varyingInt1

m_varyingInt1 = let
    varInt = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 | ID));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt1) # NOT overparameterized
#VarCorr(m_varyingInt1)
#last(m_varyingInt1.λ)

```
**ID** is suitable as a random effect. Next up, we will explore random slope effects.

### Exploring random effects structure of the model
 We start by building the most complex random effects structure around **ID** (just dumping all of the fixed effects in the varying slope).

```{julia}
#| label: m_varyingSlope_complex

m_varyingSlope_complex = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex)  # Overparameterized
```
We detect singularity. We can throw the interaction term out of the random slopes.

```{julia}
#| label: m_varyingSlope_complex_ni

m_varyingSlope_complex_ni = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_ni)  # Overparameterized
```
Still singular.

Stating zerocorr.
```{julia}
#| label: m_varyingSlope_complex_zc

m_varyingSlope_complex_zc = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_zc)  # Overparameterized
```
That didn't do it.

We will now start to delete individual random slopes...

Throwing out block:
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope1)  # Overparameterized
```

Throwing out N_visible_drift_tiles:
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope2)  # Overparameterized
``` 

Throwing out N_visible_obstacles:
```{julia}
#| label: m_varyingSlope3

m_varyingSlope3 = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope3)  # Overparameterized
```

Only keeping a single random slope

```{julia}
#| label: m_varyingSlope_block

m_varyingSlope_block = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_block)  # Overparameterized
```

```{julia}
#| label: m_varyingSlope_drift_tiles

m_varyingSlope_drift_tiles = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_drift_tiles)  # NOT overparameterized
```
That one works.

```{julia}
#| label: m_varyingSlope_obs

m_varyingSlope_obs = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_obs)  # NOT overparameterized
```
That one as well.

Throwing models against each other.
```{julia}

gof_summary = let
  nms = [:m_varyingInt1, :m_varyingSlope_obs]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingInt1, m_varyingSlope_obs)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_obs wins: random slope for obstacles may be assumed.

```{julia}

gof_summary = let
  nms = [:m_varyingInt1, :m_varyingSlope_drift_tiles]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingInt1, m_varyingSlope_drift_tiles)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_drift_tiles only slightly wins against the only varying intercept model. We will stick to m_varyingSlope_obs.


## Model selection

```{julia}
#| label: selected model

m_varyingSlope_obs = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_obs)  # NOT overparameterized
```

Finally taking a look at the main effects within the selected model:
```{julia}

VarCorr(m_varyingSlope_obs)

```

## Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for model m_varyingSlope_complex
#| label: fig-cm_varyingSlope
#|
cm_varyingSlope = first(ranefinfo(m_varyingSlope_obs));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingSlope; orderby=1)
```

## Shrinkage plot

```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), m_varyingSlope_obs)

```

## Bootstrapping

```{julia}
samples = parametricbootstrap(RNG, N_iterations, m_varyingSlope_obs)
tbl = samples.tbl
```

### Plotting
Taking a look at the distributions of the estimates for the main effects:

Let's first take a look into the bounds
```{julia}
confint(samples)
```

Now let's plot the bounds (without intercept) to visualize when 0 is within the bounds (meaning no significance).
```{julia}
ridgeplot(samples; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Fixation duration (distant fixations)")
```
no significant effects... **N_visible_drift_tiles** is scratching the 0-line...

# Modeling fixation location - distance to spaceship

# Testing random effects

```{julia}
#| label: m_varyingInt_

m_varyingInt_ = let
    varInt = @formula(1/distance_to_spaceship ~ N_visible_obstacles + N_visible_drift_tiles * block +
    (1 | ID));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt_)  # NOT overparameterized
#VarCorr(m_varyingInt_)
#last(m_varyingInt_.λ)
```

**ID** will be our sole random effect. Next up is exploring random slope.

```{julia}
#| label: m_varyingSlope_complex

m_varyingSlope_complex = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex)  # Overparameterized
```

Deleting interaction term from random slopes.
```{julia}
#| label: m_varyingSlope_complex_ni

m_varyingSlope_complex_ni = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_ni)  # Overparameterized
```

Stating zerocorr without interaction term.
```{julia}
#| label: m_varyingSlope_zc

m_varyingSlope_zc = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc)  # NOT overparameterized
```
This is the most complex model that we can build. Proceeding from here.

Trying to add the interaction effect again. Stating zerocorr with interaction term.
```{julia}
#| label: m_varyingSlope__zc

m_varyingSlope__zc = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles * N_visible_drift_tiles + block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope__zc)  # Overparameterized
```

## Deleting individual random slopes

Deleting N_visible_obstacles from random slopes.
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope1)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope1]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope1)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_zc is favored by both BIC and AIC.

Deleting block.
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles * N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope2)  # NOT overparameterized
```

Throwing models against each other:
```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope2]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope2)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC (or AIC), m_varyingSlope_zc beats the other model.

Deleting N_visible_drift_tiles
```{julia}
#| label: m_varyingSlope3

m_varyingSlope3 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope3)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope3]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope3)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope3 is favored.

## Model selection
We will proceed with m_varyingSlope3 for hypothesis testing

```{julia}
#| label: selected model

m_varyingSlope3 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope3)  # NOT overparameterized
```

Taking our first look at the main effects.
```{julia}

VarCorr(m_varyingSlope3)

```

## Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for model m_varyingSlope_complex
#| label: fig-cm_varyingSlope
#|
cm_varyingSlope = first(ranefinfo(m_varyingSlope3));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingSlope; orderby=1)
```

## Shrinkage plot

```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), m_varyingSlope3)

```
We see aggressive adjustments. We will look how the effects turn out to be in the end.

## Bootstrapping

```{julia}
samples = parametricbootstrap(RNG, N_iterations, m_varyingSlope3)
tbl = samples.tbl
```

### Plotting
Taking a look at the distributions of the estimates for the main effects:

Let's first take a look into the bounds
```{julia}
confint(samples)
```

Now let's plot the bounds (without intercept) to visualize when 0 is within the bounds (meaning no significance).
```{julia}
ridgeplot(samples; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to agent (distant fixations)")
```
We only see a main effects for **N_visible_obstacles** (0.000326151, 0.00142114). 

# Modeling fixation location - distance to closest obstacle

```{julia}
my_cake = Dict(
  :ID => Grouping(),
  :N_visible_obstacles => Grouping(),
  :block => HypothesisCoding(
    [
      -1 +1 0
      -1 0 +1
    ];
    levels=["no_drift", "fake", "invisible"],
    labels=["fake-none", "invisible-none"],
  ),
);
```

# Testing random effects
**ID** & **N_visible_obstacles** as random intercept effects.
```{julia}
#| label: m_varyingInt_

m_varyingInt_ = let
    varInt = @formula(log(Dist_to_closest_obstacles) ~  N_visible_drift_tiles * block +
    (1 | ID) +
    (1 | N_visible_obstacles));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt_)  # NOT overparameterized
#VarCorr(m_varyingInt_)
#last(m_varyingInt_.λ)
```

We will keep both random intercepts. Next up is exploring random slope.

Building most complex model:
```{julia}
#| label: m_varyingSlope_complex

m_varyingSlope_complex = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    (1 + N_visible_drift_tiles * block | ID) +
    (1 + N_visible_drift_tiles * block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex)  # Overparameterized
```

Deleting interaction term from random slopes.
```{julia}
#| label: m_varyingSlope_complex_ni

m_varyingSlope_complex_ni = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    (1 + N_visible_drift_tiles + block | ID) +
    (1 + N_visible_drift_tiles + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_ni)  # Overparameterized
```

Stating zerocorr with interaction term.
```{julia}
#| label: m_varyingSlope_zc

m_varyingSlope_zc = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles + block | ID) +
    zerocorr(1 + N_visible_drift_tiles + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc)  # NOT overparameterized
```
Proceeding with m_varyingSlope_zc. It is the most complex model that we can build.

Zerocorr with interaction term.
```{julia}
#| label: m_varyingSlope__zc

m_varyingSlope__zc = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles * block | ID) +
    zerocorr(1 + N_visible_drift_tiles * block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope__zc)  # Overparameterized
```

## Deleting individual random slopes

Deleting N_visible_drift_tiles from random slopes.
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + block | ID) +
    zerocorr(1 + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope1)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope1]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope1)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope1 is favored by both BIC and AIC.

Deleting block (drift type).
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles | ID) +
    zerocorr(1 + N_visible_drift_tiles | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope2)  # NOT overparameterized
```

Throwing models against each other:
```{julia}

gof_summary = let
  nms = [:m_varyingSlope1, :m_varyingSlope2]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope1, m_varyingSlope2)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC, m_varyingSlope1 slightly beats the other model (even more so when referring to AIC).

Testing against the only varying intercept model
```{julia}

gof_summary = let
  nms = [:m_varyingSlope1, :m_varyingInt_]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope1, m_varyingInt_)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
But m_varyingInt_ is still the best model...

## Model selection
We will refer to m_varyingInt_ for hypothesis testing.

```{julia}
#| label: selected model

m_varyingInt_ = let
    varInt = @formula(log(Dist_to_closest_obstacles) ~  N_visible_drift_tiles * block +
    (1 | ID) +
    (1 | N_visible_obstacles));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt_)  # NOT overparameterized
```

Taking our first look at the main effects.
```{julia}

VarCorr(m_varyingInt_)

```

## Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for the selected model
#| label: fig-cm_selected
#|
cm_varyingInt = first(ranefinfo(m_varyingInt_));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingInt; orderby=1)
```

## Bootstrapping

```{julia}
samples = parametricbootstrap(RNG, N_iterations, m_varyingInt_)
tbl = samples.tbl
```

### Plotting
Taking a look at the distributions of the estimates for the main effects:

Let's first take a look into the bounds
```{julia}
confint(samples)
```

Now let's plot the bounds (without intercept) to visualize when 0 is within the bounds (meaning no significance).
```{julia}
ridgeplot(samples; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to closest obstacle (distant fixations)")
```
We see a main effect for **N_visible_drift_tiles** (-0.148282, -0.0478759), decreasing the distance to the closest obstacle with increasing N.
