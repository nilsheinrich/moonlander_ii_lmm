---
title: "Nils Wendel Heinrich: Distant Fixations"
subtitle: "Moonlander II - Analysis"
author: "Nils Wendel Heinrich"
date: "2023-10-24"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options:
  chunk_output_type: console
jupyter: julia-1.9
---

# Description
2 Covariates (continuous variables we believe affect the predicted variable) - N_visible_obstacles & N_visible_drift_tiles
1 Fixed Effect (categorical variable) -block

# Setup

## Packages

```{julia}
#| label: packages

using Arrow
using AlgebraOfGraphics
using CairoMakie
using DataFrames
using DataFrameMacros
using MixedModels
using MixedModelsMakie
using Random

CairoMakie.activate!(; type="svg");
```

```{julia}
#| label: constants
const RNG = MersenneTwister(36)
N_iterations = 10000

const AoG = AlgebraOfGraphics;
```

# Modeling fixation duration

## Code book
possible random effect: **ID** (the subject itself).

```{julia}
#| label: data

my_data = DataFrame(Arrow.Table("data/Experiment2_DistantFixations.arrow"))
my_data = dropmissing(my_data, [:N_visible_obstacles, :N_visible_drift_tiles])

# Filtering saccades with no amplitude
my_data = my_data[(my_data.fixation_duration .>= 0.0125), :]
#eliminating fixations outside of game boarders
my_data = my_data[(my_data.distance_to_spaceship .< 16.63762484977781), :]

describe(my_data)
```

### Contrasts

We will declare **ID** as a grouping variable as well as define the effects coding for the discrete covariate block.

#### Hypothesis Coding
```{julia}
my_cake = Dict(
  :ID => Grouping(),
  :block => HypothesisCoding(
    [
      -1 +1 0
      -1 0 +1
    ];
    levels=["no_drift", "fake", "invisible"],
    labels=["fake-none", "invisible-none"],
  ),
);
```

# Modeling fixation duration

## Building various models

### Only varying intercept LMM

Varying intercept for **ID**:
```{julia}
#| label: m_varyingInt1

m_varyingInt1 = let
    varInt = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 | ID));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt1) # NOT overparameterized
#VarCorr(m_varyingInt1)
#last(m_varyingInt1.λ)

```
**ID** is suitable as a random effect. Next up, we will explore random slope effects.

### Exploring random effects structure of the model
 We start by building the most complex random effects structure around **ID** (just dumping all of the fixed effects in the varying slope).

```{julia}
#| label: m_varyingSlope_complex

m_varyingSlope_complex = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex)  # Overparameterized
```
We detect singularity. We can throw the interaction term out of the random slopes.

```{julia}
#| label: m_varyingSlope_complex_ni

m_varyingSlope_complex_ni = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_ni)  # Not overparameterized
```
This one converges.

Stating zerocorr.
```{julia}
#| label: m_varyingSlope_complex_zc

m_varyingSlope_complex_zc = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_zc)  # Not overparameterized
```

We will throw the two complex models with exhausted random effects structure against each other.

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_complex_ni, :m_varyingSlope_complex_zc]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_complex_ni, m_varyingSlope_complex_zc)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC, m_varyingSlope_complex_zc wins (agrees with AIC).

Putting interaction term back in while zerocorr
```{julia}
#| label: m_varyingSlope_complex_zc_in

m_varyingSlope_complex_zc_in = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_zc_in)  # Not overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_complex_zc_in, :m_varyingSlope_complex_zc]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_complex_zc_in, m_varyingSlope_complex_zc)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Interaction term in random effects can be neglected. Proceeding with m_varyingSlope_complex_zc.

We will now start to delete individual random slopes...

Throwing out block:
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope1)  # Not overparameterized
```

Throwing out N_visible_drift_tiles:
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope2)  # Not overparameterized
``` 

Throwing out N_visible_obstacles:
```{julia}
#| label: m_varyingSlope3

m_varyingSlope3 = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope3)  # Not overparameterized
```

Model comparison:
```{julia}

gof_summary = let
  nms = [:m_varyingSlope_complex_zc, :m_varyingSlope1, :m_varyingSlope2, :m_varyingSlope3]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_complex_zc, m_varyingSlope1, m_varyingSlope2, m_varyingSlope3)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_complex_zc is still favoured.

## Model selection
We will refer to m_varyingSlope_complex_zc for hypothesis testing as reducing model complexity only leads to a worse information criterion.

```{julia}
#| label: selected model

m_varyingSlope_complex_zc = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_zc)  # NOT overparameterized
```

Finally taking a look at the main effects within the selected model:
```{julia}

VarCorr(m_varyingSlope_complex_zc)

```

## Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for model m_varyingSlope_complex
#| label: fig-cm_varyingSlope
#|
cm_varyingSlope = first(ranefinfo(m_varyingSlope_complex_zc));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingSlope; orderby=1)
```

## Shrinkage plot

```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), m_varyingSlope_complex_zc)

```

## Bootstrapping

```{julia}
samples = parametricbootstrap(RNG, N_iterations, m_varyingSlope_complex_zc)
tbl = samples.tbl
```

### Plotting
Taking a look at the distributions of the estimates for the main effects:

Let's first take a look into the bounds
```{julia}
confint(samples)
```

Now let's plot the bounds (without intercept) to visualize when 0 is within the bounds (meaning no significance).
```{julia}
ridgeplot(samples; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Fixation duration (distant fixations)")
```
**N_visible_obstacles** significantly increases fixation duration in distant fixations (0.00815087, 0.0355438).

# Modeling fixation location - distance to spaceship

## Testing random effects

```{julia}
#| label: m_varyingInt_

m_varyingInt_ = let
    varInt = @formula(1/distance_to_spaceship ~ N_visible_obstacles + N_visible_drift_tiles * block +
    (1 | ID));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt_)  # NOT overparameterized
#VarCorr(m_varyingInt_)
#last(m_varyingInt_.λ)
```

**ID** will be our sole random effect. Next up is exploring random slope.

```{julia}
#| label: m_varyingSlope_complex

m_varyingSlope_complex = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex)  # Overparameterized
```

Deleting interaction term from random slopes.
```{julia}
#| label: m_varyingSlope_complex_ni

m_varyingSlope_complex_ni = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    (1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_ni)  # Not overparameterized
```

Stating zerocorr without interaction term.
```{julia}
#| label: m_varyingSlope_zc

m_varyingSlope_zc = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc)  # NOT overparameterized
```
This are the most complex models that we can build. We will compare them up next.

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope_complex_ni]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope_complex_ni)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_zc is favored by BIC (not by AIC though). Proceeding with m_varyingSlope_zc.

Trying to add the interaction effect again. Stating zerocorr with interaction term.
```{julia}
#| label: m_varyingSlope_zc_in

m_varyingSlope_zc_in = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles * N_visible_drift_tiles + block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc_in)  # Not overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope_zc_in]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope_zc_in)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
The interaction term is favored. Proceeding from here.

## Deleting individual random slopes

Deleting N_visible_obstacles from random slopes.
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope1)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc_in, :m_varyingSlope1]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc_in, m_varyingSlope1)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_zc_in wins in terms of both BIC and AIC.

Deleting block.
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles * N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope2)  # NOT overparameterized
```

Throwing models against each other:
```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc_in, :m_varyingSlope2]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc_in, m_varyingSlope2)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC (or AIC), m_varyingSlope_zc_in beats the other model.

Deleting N_visible_drift_tiles
```{julia}
#| label: m_varyingSlope3

m_varyingSlope3 = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope3)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc_in, :m_varyingSlope3]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc_in, m_varyingSlope3)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_zc_in is still favored.

## Model selection
We will proceed with m_varyingSlope_zc_in for hypothesis testing

```{julia}
#| label: selected model

m_varyingSlope_zc_in = let
    varSlop = @formula(1/distance_to_spaceship ~ 1 + N_visible_obstacles + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles * block | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc_in)  # NOT overparameterized
```

Taking our first look at the main effects.
```{julia}

VarCorr(m_varyingSlope_zc_in)

```

## Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for model m_varyingSlope_complex
#| label: fig-cm_varyingSlope
#|
cm_varyingSlope = first(ranefinfo(m_varyingSlope_zc_in));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingSlope; orderby=1)
```

## Shrinkage plot

```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), m_varyingSlope_zc_in)

```
We see aggressive adjustments. We will look how the effects turn out to be in the end.

## Bootstrapping

```{julia}
samples = parametricbootstrap(RNG, N_iterations, m_varyingSlope_zc_in)
tbl = samples.tbl
```

### Plotting
Taking a look at the distributions of the estimates for the main effects:

Let's first take a look into the bounds
```{julia}
confint(samples)
```

Now let's plot the bounds (without intercept) to visualize when 0 is within the bounds (meaning no significance).
```{julia}
ridgeplot(samples; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to agent (distant fixations)")
```
Significant main effects for...
**N_visible_obstacles** (0.000345499, 0.00107769)
**N_visible_drift_tiles** (0.00104466, 0.00587386)
both increasing distance to agent in distant fixations.

# Modeling fixation location - distance to closest obstacle

```{julia}
my_cake = Dict(
  :ID => Grouping(),
  :N_visible_obstacles => Grouping(),
  :block => HypothesisCoding(
    [
      -1 +1 0
      -1 0 +1
    ];
    levels=["no_drift", "fake", "invisible"],
    labels=["fake-none", "invisible-none"],
  ),
);
```

# Testing random effects
**ID** & **N_visible_obstacles** as random intercept effects.
```{julia}
#| label: m_varyingInt_

m_varyingInt_ = let
    varInt = @formula(log(Dist_to_closest_obstacles) ~  N_visible_drift_tiles * block +
    (1 | ID) +
    (1 | N_visible_obstacles));
    fit(MixedModel, varInt, my_data; contrasts=my_cake);
  end

issingular(m_varyingInt_)  # NOT overparameterized
#VarCorr(m_varyingInt_)
#last(m_varyingInt_.λ)
```

We will keep both random intercepts. Next up is exploring random slope.

Building most complex model:
```{julia}
#| label: m_varyingSlope_complex

m_varyingSlope_complex = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    (1 + N_visible_drift_tiles * block | ID) +
    (1 + N_visible_drift_tiles * block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex)  # Overparameterized
```

Deleting interaction term from random slopes.
```{julia}
#| label: m_varyingSlope_complex_ni

m_varyingSlope_complex_ni = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    (1 + N_visible_drift_tiles + block | ID) +
    (1 + N_visible_drift_tiles + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_complex_ni)  # Not overparameterized
```

Stating zerocorr without interaction term.
```{julia}
#| label: m_varyingSlope_zc

m_varyingSlope_zc = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles + block | ID) +
    zerocorr(1 + N_visible_drift_tiles + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope_complex_ni]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope_complex_ni)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
m_varyingSlope_zc is favored by BIC (not by AIC though). Proceeding with m_varyingSlope_zc.

Zerocorr with interaction term.
```{julia}
#| label: m_varyingSlope_zc_in

m_varyingSlope_zc_in = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles * block | ID) +
    zerocorr(1 + N_visible_drift_tiles * block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc_in)  # Overparameterized
```

## Deleting individual random slopes

Deleting N_visible_drift_tiles from random slopes.
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + block | ID) +
    zerocorr(1 + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope1)  # NOT overparameterized
```

Deleting block (drift type).
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles | ID) +
    zerocorr(1 + N_visible_drift_tiles | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope2)  # NOT overparameterized
```

Throwing models against each other:
```{julia}

gof_summary = let
  nms = [:m_varyingSlope_zc, :m_varyingSlope1, :m_varyingSlope2]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_zc, m_varyingSlope1, m_varyingSlope2)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC, m_varyingSlope_zc slightly beats the other models (although is is close to m_varyingSlope2). 

## Model selection
We will refer to m_varyingSlope_zc for hypothesis testing.

```{julia}
#| label: selected model

m_varyingSlope_zc = let
    varSlop = @formula(log(Dist_to_closest_obstacles) ~ 1 + N_visible_drift_tiles * block + 
    zerocorr(1 + N_visible_drift_tiles + block | ID) +
    zerocorr(1 + N_visible_drift_tiles + block | N_visible_obstacles));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zc)  # NOT overparameterized
```

Taking our first look at the main effects.
```{julia}

VarCorr(m_varyingSlope_zc)

```

## Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for the selected model
#| label: fig-cm_selected
#|
cm_varyingInt = first(ranefinfo(m_varyingSlope_zc));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingInt; orderby=1)
```

## Bootstrapping

```{julia}
samples = parametricbootstrap(RNG, N_iterations, m_varyingSlope_zc)
tbl = samples.tbl
```

### Plotting
Taking a look at the distributions of the estimates for the main effects:

Let's first take a look into the bounds
```{julia}
confint(samples)
```

Now let's plot the bounds (without intercept) to visualize when 0 is within the bounds (meaning no significance).
```{julia}
ridgeplot(samples; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to closest obstacle (distant fixations)")
```
Significant main effect:
**N_visible_drift_tiles** (-0.173817, -0.067387)
**block: fake vs. none** (0.00909314, 0.0604689)
**block: invisible vs. none** (0.00613109, 0.0530426)
